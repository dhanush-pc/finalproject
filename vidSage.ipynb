{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLqDDI6szjzpZcBp2QiXWX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanush-pc/finalproject/blob/main/vidSage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7jSnIaR760V",
        "outputId": "87a671ef-a703-4acf-9cea-0c6c78ca8230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GraVi-T'...\n",
            "remote: Enumerating objects: 178, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 178 (delta 16), reused 16 (delta 14), pack-reused 142 (from 1)\u001b[K\n",
            "Receiving objects: 100% (178/178), 557.66 KiB | 30.98 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IntelLabs/GraVi-T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r /content/GraVi-T/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S80cmLNq8OCq",
        "outputId": "2f346098-bcce-47d6-f993-368605bda0f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html, https://data.pyg.org/whl/torch-2.5.1+cu121.html\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from -r /content/GraVi-T/requirements.txt (line 1)) (3.13.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r /content/GraVi-T/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/GraVi-T/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/GraVi-T/requirements.txt (line 4)) (1.6.1)\n",
            "Collecting torch==2.5.1 (from -r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.20.1 (from -r /content/GraVi-T/requirements.txt (line 8))\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pyg_lib (from -r /content/GraVi-T/requirements.txt (line 9))\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/pyg_lib-0.4.0%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter (from -r /content/GraVi-T/requirements.txt (line 10))\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse (from -r /content/GraVi-T/requirements.txt (line 11))\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster (from -r /content/GraVi-T/requirements.txt (line 12))\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_cluster-1.6.3%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv (from -r /content/GraVi-T/requirements.txt (line 13))\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (994 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.8/994.8 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7))\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1->-r /content/GraVi-T/requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1->-r /content/GraVi-T/requirements.txt (line 8)) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/GraVi-T/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/GraVi-T/requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/GraVi-T/requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/GraVi-T/requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/GraVi-T/requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/GraVi-T/requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/GraVi-T/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->-r /content/GraVi-T/requirements.txt (line 7)) (3.0.2)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, torch_spline_conv, torch_scatter, pyg_lib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, torch_sparse, torch_cluster, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyg_lib-0.4.0+pt25cu121 torch-2.5.1 torch_cluster-1.6.3+pt25cu121 torch_scatter-2.1.2+pt25cu121 torch_sparse-0.6.18+pt25cu121 torch_spline_conv-1.2.2+pt25cu121 torchvision-0.20.1 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smcnte6Z8dIO",
        "outputId": "f3cb8cff-17d5-453b-f9c2-908140746869"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/eccv16_dataset_tvsum_google_pool5.rar /content/GraVi-T/data/TVSum\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIBCYil18unw",
        "outputId": "cb863985-0c8b-4f05-bfa6-bb6fb2748f3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/eccv16_dataset_tvsum_google_pool5.rar\n",
            "\n",
            "Extracting  /content/GraVi-T/data/TVSum/eccv16_dataset_tvsum_google_pool5.h5     \b\b\b\b  5%\b\b\b\b 11%\b\b\b\b 17%\b\b\b\b 22%\b\b\b\b 28%\b\b\b\b 34%\b\b\b\b 39%\b\b\b\b 45%\b\b\b\b 51%\b\b\b\b 56%\b\b\b\b 62%\b\b\b\b 68%\b\b\b\b 73%\b\b\b\b 79%\b\b\b\b 85%\b\b\b\b 90%\b\b\b\b 96%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/eccv16_dataset_summe_google_pool5.rar /content/GraVi-T/data/Summe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyWrD4Pf-xA7",
        "outputId": "e4844304-dfe9-4e79-e6f5-90b1f293dbee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/eccv16_dataset_summe_google_pool5.rar\n",
            "\n",
            "Extracting  /content/GraVi-T/data/Summe/eccv16_dataset_summe_google_pool5.h5     \b\b\b\b 18%\b\b\b\b 37%\b\b\b\b 56%\b\b\b\b 74%\b\b\b\b 93%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GraVi-T/data/generate_temporal_graphs.py --dataset TVSum --features eccv16_dataset_tvsum_google_pool5 --tauf 10 --skip_factor 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI0GoJjy-6jR",
        "outputId": "d0965ada-dd26-48f1-dccf-520961531a84"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This process might take a few minutes\n",
            "Graph generation for split1 is finished\n",
            "Graph generation for split2 is finished\n",
            "Graph generation for split3 is finished\n",
            "Graph generation for split4 is finished\n",
            "Graph generation for split5 is finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GraVi-T/data/generate_temporal_graphs.py --dataset SumMe --features eccv16_dataset_summe_google_pool5 --tauf 10 --skip_factor 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj8COyX3DlgJ",
        "outputId": "53aa82e5-6373-4235-b621-e99838ecc4e0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This process might take a few minutes\n",
            "Graph generation for split1 is finished\n",
            "Graph generation for split2 is finished\n",
            "Graph generation for split3 is finished\n",
            "Graph generation for split4 is finished\n",
            "Graph generation for split5 is finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GraVi-T/gravit/train_context_reasoning.py --cfg /content/GraVi-T/configs/video-summarization/SumMe/SPELL_default.yaml --split 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmsCrLb_DxQB",
        "outputId": "9822cc5b-5ea4-4e5f-e15b-2422dbee44d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03/27/2025 14:46:04.965 SPELL_VS_SumMe_default\n",
            "03/27/2025 14:46:04.965 Saving the configuration file\n",
            "03/27/2025 14:46:04.966 Preparing a model and data loaders\n",
            "03/27/2025 14:46:05.326 Training process started\n",
            "/content/GraVi-T/gravit/datasets/dataset_context_reasoning.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(self.all_graphs[idx])\n",
            "03/27/2025 14:46:06.266 Epoch [001|040] loss_train: 0.5276, loss_val: 0.8076, best: epoch 001\n",
            "03/27/2025 14:46:06.574 Epoch [002|040] loss_train: 0.3845, loss_val: 0.4834, best: epoch 002\n",
            "03/27/2025 14:46:06.866 Epoch [003|040] loss_train: 0.3603, loss_val: 0.5897, best: epoch 002\n",
            "03/27/2025 14:46:07.189 Epoch [004|040] loss_train: 0.3405, loss_val: 0.4573, best: epoch 004\n",
            "03/27/2025 14:46:07.492 Epoch [005|040] loss_train: 0.3301, loss_val: 0.4269, best: epoch 005\n",
            "03/27/2025 14:46:07.785 Epoch [006|040] loss_train: 0.3290, loss_val: 0.4020, best: epoch 006\n",
            "03/27/2025 14:46:08.082 Epoch [007|040] loss_train: 0.3297, loss_val: 0.4082, best: epoch 006\n",
            "03/27/2025 14:46:08.367 Epoch [008|040] loss_train: 0.3233, loss_val: 0.4106, best: epoch 006\n",
            "03/27/2025 14:46:08.649 Epoch [009|040] loss_train: 0.3235, loss_val: 0.4117, best: epoch 006\n",
            "03/27/2025 14:46:08.938 Epoch [010|040] loss_train: 0.3358, loss_val: 0.4053, best: epoch 006\n",
            "03/27/2025 14:46:09.242 Epoch [011|040] loss_train: 0.3552, loss_val: 0.4423, best: epoch 006\n",
            "03/27/2025 14:46:09.530 Epoch [012|040] loss_train: 0.3354, loss_val: 0.4424, best: epoch 006\n",
            "03/27/2025 14:46:09.815 Epoch [013|040] loss_train: 0.3296, loss_val: 0.4095, best: epoch 006\n",
            "03/27/2025 14:46:10.098 Epoch [014|040] loss_train: 0.3158, loss_val: 0.4187, best: epoch 006\n",
            "03/27/2025 14:46:10.516 Epoch [015|040] loss_train: 0.3063, loss_val: 0.4294, best: epoch 006\n",
            "03/27/2025 14:46:10.884 Epoch [016|040] loss_train: 0.3054, loss_val: 0.4149, best: epoch 006\n",
            "03/27/2025 14:46:11.245 Epoch [017|040] loss_train: 0.3040, loss_val: 0.4217, best: epoch 006\n",
            "03/27/2025 14:46:11.625 Epoch [018|040] loss_train: 0.3002, loss_val: 0.4429, best: epoch 006\n",
            "03/27/2025 14:46:12.097 Epoch [019|040] loss_train: 0.2995, loss_val: 0.4164, best: epoch 006\n",
            "03/27/2025 14:46:12.494 Epoch [020|040] loss_train: 0.2994, loss_val: 0.4369, best: epoch 006\n",
            "03/27/2025 14:46:12.785 Epoch [021|040] loss_train: 0.3053, loss_val: 0.4227, best: epoch 006\n",
            "03/27/2025 14:46:13.080 Epoch [022|040] loss_train: 0.3150, loss_val: 0.5416, best: epoch 006\n",
            "03/27/2025 14:46:13.380 Epoch [023|040] loss_train: 0.3198, loss_val: 0.4574, best: epoch 006\n",
            "03/27/2025 14:46:13.669 Epoch [024|040] loss_train: 0.3019, loss_val: 0.4412, best: epoch 006\n",
            "03/27/2025 14:46:13.956 Epoch [025|040] loss_train: 0.2965, loss_val: 0.4299, best: epoch 006\n",
            "03/27/2025 14:46:14.246 Epoch [026|040] loss_train: 0.2939, loss_val: 0.4339, best: epoch 006\n",
            "03/27/2025 14:46:14.534 Epoch [027|040] loss_train: 0.2928, loss_val: 0.4315, best: epoch 006\n",
            "03/27/2025 14:46:14.825 Epoch [028|040] loss_train: 0.2912, loss_val: 0.4396, best: epoch 006\n",
            "03/27/2025 14:46:15.114 Epoch [029|040] loss_train: 0.2896, loss_val: 0.4378, best: epoch 006\n",
            "03/27/2025 14:46:15.417 Epoch [030|040] loss_train: 0.2917, loss_val: 0.4397, best: epoch 006\n",
            "03/27/2025 14:46:15.699 Epoch [031|040] loss_train: 0.3060, loss_val: 0.5066, best: epoch 006\n",
            "03/27/2025 14:46:15.979 Epoch [032|040] loss_train: 0.3143, loss_val: 0.4424, best: epoch 006\n",
            "03/27/2025 14:46:16.261 Epoch [033|040] loss_train: 0.3029, loss_val: 0.4460, best: epoch 006\n",
            "03/27/2025 14:46:16.552 Epoch [034|040] loss_train: 0.2964, loss_val: 0.4336, best: epoch 006\n",
            "03/27/2025 14:46:16.832 Epoch [035|040] loss_train: 0.2888, loss_val: 0.4264, best: epoch 006\n",
            "03/27/2025 14:46:17.113 Epoch [036|040] loss_train: 0.2869, loss_val: 0.4271, best: epoch 006\n",
            "03/27/2025 14:46:17.402 Epoch [037|040] loss_train: 0.2864, loss_val: 0.4332, best: epoch 006\n",
            "03/27/2025 14:46:17.686 Epoch [038|040] loss_train: 0.2848, loss_val: 0.4379, best: epoch 006\n",
            "03/27/2025 14:46:17.974 Epoch [039|040] loss_train: 0.2839, loss_val: 0.4416, best: epoch 006\n",
            "03/27/2025 14:46:18.258 Epoch [040|040] loss_train: 0.2871, loss_val: 0.4395, best: epoch 006\n",
            "03/27/2025 14:46:18.259 Training finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GraVi-T/gravit/train_context_reasoning.py --cfg /content/GraVi-T/configs/video-summarization/TVSum/SPELL_default.yaml --split 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PINQAB1jEahH",
        "outputId": "64612249-998c-4869-e412-3547aea66314"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03/27/2025 15:06:42.429 SPELL_VS_TVSum_default\n",
            "03/27/2025 15:06:42.429 Saving the configuration file\n",
            "03/27/2025 15:06:42.432 Preparing a model and data loaders\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GraVi-T/gravit/train_context_reasoning.py\", line 118, in <module>\n",
            "    train(cfg)\n",
            "  File \"/content/GraVi-T/gravit/train_context_reasoning.py\", line 36, in train\n",
            "    train_loader = DataLoader(GraphDataset(os.path.join(path_graphs, 'train')), batch_size=cfg['batch_size'], shuffle=True)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch_geometric/loader/dataloader.py\", line 87, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 376, in __init__\n",
            "    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\", line 164, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: num_samples should be a positive integer value, but got num_samples=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GraVi-T/gravit/evaluate.py --exp_name SPELL_VS_SumMe_default --eval_type VS_max --split 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC5PoB7QG_nq",
        "outputId": "1ddaf0d4-9b18-4045-8dae-9432e2fdc7b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03/27/2025 15:01:09.345 SPELL_VS_SumMe_default\n",
            "03/27/2025 15:01:09.345 ./results/SPELL_VS_SumMe_default/split4\n",
            "03/27/2025 15:01:09.345 Preparing a model and data loaders\n",
            "03/27/2025 15:01:09.539 Loading the trained model\n",
            "/content/GraVi-T/gravit/evaluate.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(os.path.join(path_result, 'ckpt_best.pt'), map_location=torch.device('cpu'))\n",
            "03/27/2025 15:01:09.545 Retrieving the formatting dictionary\n",
            "03/27/2025 15:01:09.546 Evaluation process started\n",
            "/content/GraVi-T/gravit/datasets/dataset_context_reasoning.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(self.all_graphs[idx])\n",
            "03/27/2025 15:01:09.768 [0001|0005] processed\n",
            "03/27/2025 15:01:09.781 [0002|0005] processed\n",
            "03/27/2025 15:01:09.792 [0003|0005] processed\n",
            "03/27/2025 15:01:09.800 [0004|0005] processed\n",
            "03/27/2025 15:01:09.812 [0005|0005] processed\n",
            "03/27/2025 15:01:09.812 Computing the evaluation score\n",
            "/content/GraVi-T/gravit/utils/eval_tool.py:495: RuntimeWarning: overflow encountered in scalar add\n",
            "  precision = sum(tp)/sum(pred_summary)\n",
            "/content/GraVi-T/gravit/utils/eval_tool.py:496: RuntimeWarning: overflow encountered in scalar add\n",
            "  recall = sum(tp)/sum(user_summary)\n",
            "03/27/2025 15:01:09.977 VS_max evaluation finished: F1-Score = 262.083719600961, Tau = 0.10937077318512159, Rho = 0.14497365956650338\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GraVi-T/gravit/evaluate.py --exp_name SPELL_VS_TVSum_default --eval_type VS_max --split 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pl0OzyCHJF2",
        "outputId": "682f01e6-a188-41f5-bd36-fe23f2d3fdad"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03/27/2025 15:01:57.238 SPELL_VS_TVSum_default\n",
            "03/27/2025 15:01:57.238 ./results/SPELL_VS_TVSum_default/split4\n",
            "03/27/2025 15:01:57.238 Preparing a model and data loaders\n",
            "03/27/2025 15:01:57.431 Loading the trained model\n",
            "/content/GraVi-T/gravit/evaluate.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(os.path.join(path_result, 'ckpt_best.pt'), map_location=torch.device('cpu'))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GraVi-T/gravit/evaluate.py\", line 121, in <module>\n",
            "    all_eval_results.append(evaluate(cfg))\n",
            "                            ^^^^^^^^^^^^^\n",
            "  File \"/content/GraVi-T/gravit/evaluate.py\", line 50, in evaluate\n",
            "    state_dict = torch.load(os.path.join(path_result, 'ckpt_best.pt'), map_location=torch.device('cpu'))\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1319, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 659, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 640, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './results/SPELL_VS_TVSum_default/split4/ckpt_best.pt'\n"
          ]
        }
      ]
    }
  ]
}